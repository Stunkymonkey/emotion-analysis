{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SSEC trained vs human annotation\n",
    "\n",
    "We train a feature-based ML model on the SSEC corpus, which is annotated with Plutchik's eight emotions (multi-label).\n",
    "The trained model will then be evaluated on a corpus with our own annotation to compare the human annotations with learned\n",
    "labels from the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import nltk\n",
    "from sklearn.metrics import multilabel_confusion_matrix as mcm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Corpus data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "# File with all corpora\n",
    "with open('unified-dataset.json', encoding='utf-8') as f:\n",
    "    data_source = pandas.read_json(f, lines=True)\n",
    "\n",
    "# Select only SSEC corpus\n",
    "data_source = data_source.loc[(data_source['source'] == \"ssec\")]\n",
    "# Convert emotions dict to columns\n",
    "data_source = data_source.join(data_source['emotions'].apply(pandas.Series))\n",
    "# Remove all columns except for the text and emotion labels\n",
    "data_source = data_source.drop(columns=['source', 'VAD', 'split', 'domain', 'labeled', 'optional', 'annotation_procedure',\n",
    "                      'emotion_model', 'emotions', 'love', 'noemo', 'confusion', 'shame', 'guilt'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "The texts are tokenized, shortened to their lemma and stopwords are removed. We do not remove 'not', as it could invert an emotion if standing before an emotion indicator)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "def preprocessing(df: pandas.DataFrame):\n",
    "    toks = list()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Preparation of stopwords\n",
    "        stops = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "        stops.remove(\"not\")\n",
    "        for char in {\"#\", \"@\", \"semst\", \"&\", \"!\", \"ยง\", \"$\", \"%\", \"/\", \"=\", \"?\", \".\", \",\", \";\", \":\", \"-\", \"<\", \">\", \"+\", \"~\", \"'\", \"''\", '\"', \"(\",\")\"}:\n",
    "            stops.add(char)\n",
    "        # Tokenization and stemming with NLTK\n",
    "        stemmer = nltk.stem.LancasterStemmer()\n",
    "        tokens = [stemmer.stem(word).lower() for word in nltk.tokenize.word_tokenize(df[\"text\"][index])]\n",
    "        tokens = [word for word in tokens if word not in stops]\n",
    "        toks.append(tokens)\n",
    "    # Replacing the raw text with the processed version\n",
    "    toks = pandas.DataFrame({\"text\": toks}, index=df[\"id\"])\n",
    "    return df.assign(text = toks[\"text\"])\n",
    "\n",
    "data_source = preprocessing(data_source)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature extraction\n",
    "To complete the preprocessing, the now tokenized texts must be converted into a feature set for each multi-label annotation. Each feature set is comprised of the individual tokens as bigrams, with a one padding dummy on each end."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "# Function to set the truth values of occuring words to True\n",
    "def features(corpus):\n",
    "    # Output: dictionary of all feature set lists for each emotion\n",
    "    # {emotion: [(fs1, label), (fs2,label),...],...} with (fs, l)= ({word:True/False, word...}, 1/0)\n",
    "    out_features = {emotion : list() for emotion in [\"joy\", \"sadness\", \"trust\", \"disgust\", \"anger\", \"fear\", \"surprise\", \"anticipation\"]}\n",
    "    for index in range(1,100):\n",
    "        # Populating the feature sets as dictionaries with truth values for all words in the training data\n",
    "        feature_dicts = {word: False for text in data_source[\"text\"] for word in text}\n",
    "        for word in corpus[\"text\"][index]:\n",
    "            feature_dicts[word] = True\n",
    "        for emotion in out_features:\n",
    "            if corpus[emotion][index] == 1:\n",
    "                    out_features[emotion].append((feature_dicts, 1))\n",
    "            else:\n",
    "                out_features[emotion].append((feature_dicts, 0))\n",
    "    return out_features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "To train the model, Naive Bayes is used, which is normally used for single label learning.\n",
    "Therefore, the model is adjusted to learn and compute the probabilities for each emotion separately.\n",
    "That way, to annotate a text, the classifier for each emotion makes a pass over the text (8 passes)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "class MultiLabel:\n",
    "\n",
    "    def train(self, train_data):\n",
    "        self.train_set = train_data\n",
    "\n",
    "        self.joy = nltk.classify.NaiveBayesClassifier.train(train_data[\"joy\"])\n",
    "        self.sadness = nltk.classify.NaiveBayesClassifier.train(train_data[\"sadness\"])\n",
    "        self.trust = nltk.classify.NaiveBayesClassifier.train(train_data[\"trust\"])\n",
    "        self.disgust = nltk.classify.NaiveBayesClassifier.train(train_data[\"disgust\"])\n",
    "        self.anger = nltk.classify.NaiveBayesClassifier.train(train_data[\"anger\"])\n",
    "        self.fear = nltk.classify.NaiveBayesClassifier.train(train_data[\"fear\"])\n",
    "        self.surprise = nltk.classify.NaiveBayesClassifier.train(train_data[\"surprise\"])\n",
    "        self.anticipation = nltk.classify.NaiveBayesClassifier.train(train_data[\"anticipation\"])\n",
    "\n",
    "        self.emos = {\"joy\": self.joy,\n",
    "                \"sadness\": self.sadness,\n",
    "                \"trust\": self.trust,\n",
    "                \"disgust\": self.disgust,\n",
    "                \"anger\": self.anger,\n",
    "                \"fear\": self.fear,\n",
    "                \"surprise\": self.surprise,\n",
    "                \"anticipation\": self.anticipation\n",
    "                }\n",
    "    def accuracy(self, test_set):\n",
    "        acc = {\n",
    "        \"joy\" : nltk.classify.accuracy(self.joy, test_set[\"joy\"]),\n",
    "        \"sadness\" : nltk.classify.accuracy(self.sadness, test_set[\"sadness\"]),\n",
    "        \"trust\" : nltk.classify.accuracy(self.trust, test_set[\"trust\"]),\n",
    "        \"disgust\" : nltk.classify.accuracy(self.disgust, test_set[\"disgust\"]),\n",
    "        \"anger\" : nltk.classify.accuracy(self.anger, test_set[\"anger\"]),\n",
    "        \"fear\" : nltk.classify.accuracy(self.fear, test_set[\"fear\"]),\n",
    "        \"surprise\" : nltk.classify.accuracy(self.surprise, test_set[\"surprise\"]),\n",
    "        \"anticipation\" : nltk.classify.accuracy(self.anticipation, test_set[\"anticipation\"])\n",
    "            }\n",
    "        acc[\"avg\"] = (acc[\"joy\"] + acc[\"sadness\"] + acc[\"trust\"] + acc[\"disgust\"] + acc[\"anger\"] + acc[\"fear\"] + acc[\"surprise\"] + acc[\"anticipation\"])/8\n",
    "\n",
    "        return acc\n",
    "\n",
    "    def most_informative_feats(self, n=10):\n",
    "        return {\n",
    "            \"joy\" : self.joy.most_informative_features(n),\n",
    "            \"sadness\" : self.sadness.most_informative_features(n),\n",
    "            \"trust\" : self.trust.most_informative_features(n),\n",
    "            \"disgust\" : self.disgust.most_informative_features(n),\n",
    "            \"anger\" : self.anger.most_informative_features(n),\n",
    "            \"fear\" : self.fear.most_informative_features(n),\n",
    "            \"surprise\" : self.surprise.most_informative_features(n),\n",
    "            \"anticipation\" : self.anticipation.most_informative_features(n),\n",
    "        }\n",
    "\n",
    "    def eval(self, test_set, most_informative_features=True):\n",
    "        acc = self.accuracy(test_set)\n",
    "\n",
    "        for emotion in self.emos:\n",
    "            print(emotion.title() + f\":\\nAccuracy: {round(acc[emotion], 3)}\")\n",
    "            if most_informative_features:\n",
    "                self.emos[emotion].show_most_informative_features(n=10)\n",
    "            print(f\"{'_':_<20}\")\n",
    "\n",
    "        def extract_labels(corpus):\n",
    "            out_lab = list()\n",
    "            for emotion in corpus:\n",
    "                single_label = list()\n",
    "                for i in range(len(corpus[emotion])):\n",
    "                    if corpus[emotion][i] == 1:\n",
    "                        single_label.append([1])\n",
    "                    else: single_label.append([0])\n",
    "                if not len(out_lab):\n",
    "                    out_lab.append(single_label)\n",
    "                else:\n",
    "                    for i in range(len(out_lab)):\n",
    "                        out_lab[i].append(single_label[i])\n",
    "            return out_lab\n",
    "        \n",
    "        labels_gold = extract_labels(test_set)\n",
    "        labels_pred = list()\n",
    "        for (fs, label) in test_set[\"joy\"]:\n",
    "            label_set = list()\n",
    "            for emotion in [\"joy\", \"sadness\", \"trust\", \"disgust\", \"anger\", \"fear\", \"surprise\", \"anticipation\"]:\n",
    "                label_set.append(self.emos[emotion].classify(fs))\n",
    "            labels_pred.append(label_set)\n",
    "        accum = 0\n",
    "        for i in range(len(labels_gold)):\n",
    "            single = 0\n",
    "            for j in range(8):\n",
    "                if labels_gold[i][j]==labels_pred[i][j]:\n",
    "                    single += 1\n",
    "            accum += single/8\n",
    "        acc[\"accum\"] = accum/len(labels_gold)\n",
    "        print(\"Accumulated accuracy:\\t\", round(acc[\"accum\"], 3), \"\\nMulti-label confusion matrix\", sep=\"\")\n",
    "        #print(mcm(labels_gold, labels_pred, labels=[\"joy\", \"sadness\", \"trust\", \"disgust\", \"anger\", \"fear\", \"surprise\", \"anticipation\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splitting the data\n",
    "To train the model, 80% of the SSEC corpus is used while the remaining 20% are held out for evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "# Splitting the corpus into training and testing data in a 8/2 ratio\n",
    "split = int(data_source.shape[0]*0.8)\n",
    "corpus_train = data_source.loc[data_source[\"id\"] <= 21051+split]\n",
    "corpus_test = data_source.loc[data_source[\"id\"] > 21051+split]\n",
    "\n",
    "# Dictionary for the training feature sets for all emotions:\n",
    "train_features = features(corpus_train)\n",
    "\n",
    "ssec_trained = MultiLabel()\n",
    "ssec_trained.train(train_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n",
    "The trained tagger is evaluated first on a held back part of the corpus. As part of the evaluation,\n",
    "the accuracy and the most informative features for each label are calculated."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joy\n",
      "Most Informative Features\n",
      "                 lovewin = True                1 : 0      =     23.0 : 1.0\n",
      "                    amaz = True                1 : 0      =     18.7 : 1.0\n",
      "                   thank = True                1 : 0      =     16.2 : 1.0\n",
      "   makeamericagreatagain = True                1 : 0      =     12.2 : 1.0\n",
      "                     lov = True                1 : 0      =     11.6 : 1.0\n",
      "                  awesom = True                1 : 0      =     10.0 : 1.0\n",
      "                   dream = True                1 : 0      =     10.0 : 1.0\n",
      "                   enjoy = True                1 : 0      =     10.0 : 1.0\n",
      "                    stat = True                0 : 1      =      8.9 : 1.0\n",
      "                  effect = True                0 : 1      =      8.4 : 1.0\n",
      ":\n",
      "Accuracy: 0.728\n",
      "____________________\n",
      "Sadness\n",
      "Most Informative Features\n",
      "                  victim = True                1 : 0      =      9.0 : 1.0\n",
      "                    sham = True                1 : 0      =      8.5 : 1.0\n",
      "                 liberty = True                0 : 1      =      8.0 : 1.0\n",
      "                    road = True                0 : 1      =      8.0 : 1.0\n",
      "                    abus = True                1 : 0      =      7.9 : 1.0\n",
      "   makeamericagreatagain = True                0 : 1      =      7.3 : 1.0\n",
      "                 oppress = True                1 : 0      =      7.3 : 1.0\n",
      "                  inspir = True                0 : 1      =      7.2 : 1.0\n",
      "                     war = True                1 : 0      =      6.8 : 1.0\n",
      "                    degr = True                1 : 0      =      6.7 : 1.0\n",
      ":\n",
      "Accuracy: 0.655\n",
      "____________________\n",
      "Trust\n",
      "Most Informative Features\n",
      "                    sham = True                0 : 1      =     12.1 : 1.0\n",
      "                   bring = True                1 : 0      =      9.9 : 1.0\n",
      "                    degr = True                0 : 1      =      9.6 : 1.0\n",
      "                     hot = True                0 : 1      =      9.6 : 1.0\n",
      "                     nic = True                0 : 1      =      9.6 : 1.0\n",
      "                   delet = True                0 : 1      =      7.1 : 1.0\n",
      "                   delud = True                0 : 1      =      7.1 : 1.0\n",
      "                    suck = True                0 : 1      =      7.1 : 1.0\n",
      "            election2016 = True                1 : 0      =      6.7 : 1.0\n",
      "               freeallfo = True                0 : 1      =      6.2 : 1.0\n",
      ":\n",
      "Accuracy: 0.579\n",
      "____________________\n",
      "Disgust\n",
      "Most Informative Features\n",
      "                     rap = True                1 : 0      =     29.8 : 1.0\n",
      "                hypocrit = True                1 : 0      =     13.4 : 1.0\n",
      "                    sham = True                1 : 0      =     12.5 : 1.0\n",
      "                    abus = True                1 : 0      =     11.7 : 1.0\n",
      "                   bigot = True                1 : 0      =     11.7 : 1.0\n",
      "                     jes = True                0 : 1      =     11.3 : 1.0\n",
      "                     sin = True                0 : 1      =     11.1 : 1.0\n",
      "                   lying = True                1 : 0      =      9.9 : 1.0\n",
      "    whyimnotvotingforhil = True                1 : 0      =      9.9 : 1.0\n",
      "                   idiot = True                1 : 0      =      9.6 : 1.0\n",
      ":\n",
      "Accuracy: 0.664\n",
      "____________________\n",
      "Anger\n",
      "Most Informative Features\n",
      "                     sin = True                0 : 1      =     20.4 : 1.0\n",
      "                    fuck = True                1 : 0      =     13.7 : 1.0\n",
      "                     hat = True                1 : 0      =     13.2 : 1.0\n",
      "                 teamjes = True                0 : 1      =     11.8 : 1.0\n",
      "                     rap = True                1 : 0      =     11.4 : 1.0\n",
      "                     tip = True                0 : 1      =     11.1 : 1.0\n",
      "                  awesom = True                0 : 1      =     10.9 : 1.0\n",
      "                    mary = True                0 : 1      =     10.9 : 1.0\n",
      "                 liberty = True                0 : 1      =      9.9 : 1.0\n",
      "                     lie = True                1 : 0      =      9.7 : 1.0\n",
      ":\n",
      "Accuracy: 0.707\n",
      "____________________\n",
      "Fear\n",
      "Most Informative Features\n",
      "                    risk = True                1 : 0      =     12.8 : 1.0\n",
      "                   happy = True                0 : 1      =     11.8 : 1.0\n",
      "                    temp = True                1 : 0      =     11.7 : 1.0\n",
      "                    viol = True                1 : 0      =     11.7 : 1.0\n",
      "                   agend = True                1 : 0      =     10.6 : 1.0\n",
      "                 drought = True                1 : 0      =     10.6 : 1.0\n",
      "                  harass = True                1 : 0      =     10.6 : 1.0\n",
      "                     ter = True                1 : 0      =     10.6 : 1.0\n",
      "                     hrc = True                1 : 0      =      9.5 : 1.0\n",
      "                    fear = True                1 : 0      =      9.3 : 1.0\n",
      ":\n",
      "Accuracy: 0.637\n",
      "____________________\n",
      "Surprise\n",
      "Most Informative Features\n",
      "                     wow = True                1 : 0      =     32.6 : 1.0\n",
      "                     sud = True                1 : 0      =     13.7 : 1.0\n",
      "                   assum = True                1 : 0      =     11.6 : 1.0\n",
      "                       c = True                1 : 0      =     11.6 : 1.0\n",
      "                   civil = True                1 : 0      =     11.6 : 1.0\n",
      "                    hero = True                1 : 0      =     11.6 : 1.0\n",
      "                    movy = True                1 : 0      =     11.6 : 1.0\n",
      "                   admir = True                1 : 0      =      9.5 : 1.0\n",
      "                     pen = True                1 : 0      =      9.5 : 1.0\n",
      "             prowomancho = True                1 : 0      =      9.5 : 1.0\n",
      ":\n",
      "Accuracy: 0.692\n",
      "____________________\n",
      "Anticipation\n",
      "Most Informative Features\n",
      ":\n",
      "Accuracy: 1.0\n",
      "____________________\n",
      "Accumulated accuracy:\t0.0\n",
      "Multi-label confusion matrix\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 973]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-216-a5d70ced4970>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mtest_features\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcorpus_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mssec_trained\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meval\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_features\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-214-b49a7e97aebc>\u001B[0m in \u001B[0;36meval\u001B[1;34m(self, test_set, most_informative_features)\u001B[0m\n\u001B[0;32m     89\u001B[0m         \u001B[0macc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"accum\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0maccum\u001B[0m\u001B[1;33m/\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels_gold\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Accumulated accuracy:\\t\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mround\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0macc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"accum\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"\\nMulti-label confusion matrix\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 91\u001B[1;33m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmcm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels_gold\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"joy\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"sadness\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"trust\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"disgust\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"anger\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"fear\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"surprise\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"anticipation\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     92\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp envy\\documents\\uni\\master\\ws 2020\\emotion analysis\\assignments\\assignment_02\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp envy\\documents\\uni\\master\\ws 2020\\emotion analysis\\assignments\\assignment_02\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001B[0m in \u001B[0;36mmultilabel_confusion_matrix\u001B[1;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001B[0m\n\u001B[0;32m    454\u001B[0m             [1, 2]]])\n\u001B[0;32m    455\u001B[0m     \"\"\"\n\u001B[1;32m--> 456\u001B[1;33m     \u001B[0my_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_check_targets\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    457\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0msample_weight\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    458\u001B[0m         \u001B[0msample_weight\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcolumn_or_1d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp envy\\documents\\uni\\master\\ws 2020\\emotion analysis\\assignments\\assignment_02\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001B[0m in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     81\u001B[0m     \u001B[0my_pred\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0marray\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mindicator\u001B[0m \u001B[0mmatrix\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m     \"\"\"\n\u001B[1;32m---> 83\u001B[1;33m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     84\u001B[0m     \u001B[0mtype_true\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m     \u001B[0mtype_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp envy\\documents\\uni\\master\\ws 2020\\emotion analysis\\assignments\\assignment_02\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    260\u001B[0m     \u001B[0muniques\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001B[0m\u001B[0;32m    263\u001B[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [1, 973]"
     ]
    }
   ],
   "source": [
    "test_features = features(corpus_test)\n",
    "ssec_trained.eval(test_features)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After evaluating the classifier's performance on data similar to the training data, the same classifier is evaluated\n",
    "on our own annotated corpus. Before evaluation, we can already predict a bad performance for anticipation, as the tag\n",
    "is not part of the training data and therefore will never be annotated."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joy\n",
      ":\n",
      "Accuracy: 0.434\n",
      "____________________\n",
      "Sadness\n",
      ":\n",
      "Accuracy: 0.293\n",
      "____________________\n",
      "Trust\n",
      ":\n",
      "Accuracy: 0.374\n",
      "____________________\n",
      "Disgust\n",
      ":\n",
      "Accuracy: 0.515\n",
      "____________________\n",
      "Anger\n",
      ":\n",
      "Accuracy: 0.333\n",
      "____________________\n",
      "Fear\n",
      ":\n",
      "Accuracy: 0.657\n",
      "____________________\n",
      "Surprise\n",
      ":\n",
      "Accuracy: 0.606\n",
      "____________________\n",
      "Anticipation\n",
      ":\n",
      "Accuracy: 0.98\n",
      "____________________\n",
      "Accumulated accuracy:\t0.0\n",
      "Multi-label confusion matrix\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 99]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-223-08fab1e78601>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mreddit_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpreprocessing\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreddit_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mreddit_features\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreddit_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0mssec_trained\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meval\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreddit_features\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-214-b49a7e97aebc>\u001B[0m in \u001B[0;36meval\u001B[1;34m(self, test_set, most_informative_features)\u001B[0m\n\u001B[0;32m     89\u001B[0m         \u001B[0macc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"accum\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0maccum\u001B[0m\u001B[1;33m/\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels_gold\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Accumulated accuracy:\\t\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mround\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0macc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"accum\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"\\nMulti-label confusion matrix\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 91\u001B[1;33m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmcm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels_gold\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"joy\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"sadness\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"trust\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"disgust\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"anger\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"fear\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"surprise\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"anticipation\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     92\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp envy\\documents\\uni\\master\\ws 2020\\emotion analysis\\assignments\\assignment_02\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp envy\\documents\\uni\\master\\ws 2020\\emotion analysis\\assignments\\assignment_02\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001B[0m in \u001B[0;36mmultilabel_confusion_matrix\u001B[1;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001B[0m\n\u001B[0;32m    454\u001B[0m             [1, 2]]])\n\u001B[0;32m    455\u001B[0m     \"\"\"\n\u001B[1;32m--> 456\u001B[1;33m     \u001B[0my_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_check_targets\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    457\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0msample_weight\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    458\u001B[0m         \u001B[0msample_weight\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcolumn_or_1d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp envy\\documents\\uni\\master\\ws 2020\\emotion analysis\\assignments\\assignment_02\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001B[0m in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     81\u001B[0m     \u001B[0my_pred\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0marray\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mindicator\u001B[0m \u001B[0mmatrix\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m     \"\"\"\n\u001B[1;32m---> 83\u001B[1;33m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     84\u001B[0m     \u001B[0mtype_true\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m     \u001B[0mtype_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp envy\\documents\\uni\\master\\ws 2020\\emotion analysis\\assignments\\assignment_02\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    260\u001B[0m     \u001B[0muniques\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001B[0m\u001B[0;32m    263\u001B[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [1, 99]"
     ]
    }
   ],
   "source": [
    "with open(\"on-off_average_annotation.csv\", encoding=\"utf-8\") as f:\n",
    "    reddit_data = pandas.read_csv(f, sep=\";\", header=0)\n",
    "\n",
    "reddit_data = preprocessing(reddit_data)\n",
    "reddit_features = features(reddit_data)\n",
    "ssec_trained.eval(reddit_features, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}